{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-16T15:21:13.574294Z",
     "start_time": "2025-06-16T15:21:13.565082Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T15:21:13.627686Z",
     "start_time": "2025-06-16T15:21:13.596612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def diagnose_dataframe(df, target_col=None):\n",
    "    \"\"\"Effectue un diagnostic complet d'un DataFrame\"\"\"\n",
    "\n",
    "    print(f\"\\nüìä DIAGNOSTIC G√âN√âRAL\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"M√©moire utilis√©e: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "    # Types de donn√©es\n",
    "    print(f\"\\nüìã TYPES DE DONN√âES:\")\n",
    "    print(df.dtypes.value_counts())\n",
    "\n",
    "    # Valeurs manquantes\n",
    "    print(f\"\\n‚ùì VALEURS MANQUANTES:\")\n",
    "    missing = df.isnull().sum()\n",
    "    missing_pct = (missing / len(df)) * 100\n",
    "    missing_df = pd.DataFrame({\n",
    "        'Colonne': missing.index,\n",
    "        'Manquantes': missing.values,\n",
    "        'Pourcentage': missing_pct.values\n",
    "    }).query('Manquantes > 0').sort_values('Manquantes', ascending=False)\n",
    "\n",
    "    if len(missing_df) > 0:\n",
    "        print(missing_df)\n",
    "    else:\n",
    "        print(\"‚úÖ Aucune valeur manquante\")\n",
    "\n",
    "    # Valeurs infinies\n",
    "    print(f\"\\n‚ôæÔ∏è VALEURS INFINIES:\")\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    infinite_counts = {}\n",
    "    for col in numeric_cols:\n",
    "        inf_count = np.isinf(df[col]).sum()\n",
    "        if inf_count > 0:\n",
    "            infinite_counts[col] = inf_count\n",
    "\n",
    "    if infinite_counts:\n",
    "        for col, count in infinite_counts.items():\n",
    "            print(f\"   {col}: {count} valeurs infinies\")\n",
    "    else:\n",
    "        print(\"‚úÖ Aucune valeur infinie\")\n",
    "\n",
    "    # Variables cat√©gorielles\n",
    "    print(f\"\\nüè∑Ô∏è VARIABLES CAT√âGORIELLES:\")\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "    if len(categorical_cols) > 0:\n",
    "        for col in categorical_cols:\n",
    "            unique_vals = df[col].nunique()\n",
    "            print(f\"   {col}: {unique_vals} valeurs uniques\")\n",
    "            if unique_vals <= 10:\n",
    "                print(f\"      Valeurs: {df[col].unique()}\")\n",
    "    else:\n",
    "        print(\"‚úÖ Aucune variable cat√©gorielle\")\n",
    "\n",
    "    # Variables num√©riques avec peu de valeurs uniques (potentiellement cat√©gorielles)\n",
    "    print(f\"\\nüî¢ VARIABLES NUM√âRIQUES SUSPECTES (peu de valeurs uniques):\")\n",
    "    for col in numeric_cols:\n",
    "        unique_vals = df[col].nunique()\n",
    "        if unique_vals <= 10:\n",
    "            print(f\"   {col}: {unique_vals} valeurs uniques - {df[col].unique()}\")\n",
    "\n",
    "    # Colonnes dupliqu√©es\n",
    "    print(f\"\\nüîç COLONNES DUPLIQU√âES:\")\n",
    "    duplicated_cols = []\n",
    "    for i, col1 in enumerate(df.columns):\n",
    "        for col2 in df.columns[i+1:]:\n",
    "            if df[col1].equals(df[col2]):\n",
    "                duplicated_cols.append((col1, col2))\n",
    "\n",
    "    if duplicated_cols:\n",
    "        for col1, col2 in duplicated_cols:\n",
    "            print(f\"   {col1} = {col2}\")\n",
    "    else:\n",
    "        print(\"‚úÖ Aucune colonne dupliqu√©e\")\n",
    "\n",
    "    # Statistiques pour la variable cible\n",
    "    if target_col and target_col in df.columns:\n",
    "        print(f\"\\nüéØ ANALYSE DE LA VARIABLE CIBLE '{target_col}':\")\n",
    "        print(df[target_col].value_counts())\n",
    "        print(f\"Pourcentages:\")\n",
    "        print(df[target_col].value_counts(normalize=True) * 100)"
   ],
   "id": "780e0e2fb4d214c",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T15:21:13.675806Z",
     "start_time": "2025-06-16T15:21:13.647324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_dataframe(df, target_col=None):\n",
    "    \"\"\"Nettoie automatiquement un DataFrame\"\"\"\n",
    "\n",
    "    print(f\"\\nüßπ NETTOYAGE AUTOMATIQUE\")\n",
    "    df_clean = df.copy()\n",
    "\n",
    "    # 1. Identifier et s√©parer la variable cible\n",
    "    if target_col:\n",
    "        if target_col in df_clean.columns:\n",
    "            y = df_clean[target_col]\n",
    "            # Si c'est du texte, l'encoder\n",
    "            if y.dtype == 'object':\n",
    "                print(f\"   Encodage de la variable cible '{target_col}'\")\n",
    "                if 'Not_Canceled' in y.unique():\n",
    "                    y = (y == 'Not_Canceled').astype(int)\n",
    "                else:\n",
    "                    le = LabelEncoder()\n",
    "                    y = le.fit_transform(y.fillna('Unknown'))\n",
    "            X = df_clean.drop(target_col, axis=1)\n",
    "        else:\n",
    "            print(f\"‚ùå Variable cible '{target_col}' non trouv√©e\")\n",
    "            return None, None\n",
    "    else:\n",
    "        X = df_clean\n",
    "        y = None\n",
    "\n",
    "    # 2. Traiter les variables cat√©gorielles\n",
    "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "    if len(categorical_cols) > 0:\n",
    "        print(f\"   Encodage de {len(categorical_cols)} variables cat√©gorielles\")\n",
    "        for col in categorical_cols:\n",
    "            # Remplir les valeurs manquantes\n",
    "            X[col] = X[col].fillna('Unknown')\n",
    "\n",
    "            # Encoder\n",
    "            le = LabelEncoder()\n",
    "            X[f'{col}_encoded'] = le.fit_transform(X[col])\n",
    "\n",
    "            # Supprimer la colonne originale\n",
    "            X = X.drop(col, axis=1)\n",
    "\n",
    "    # 3. G√©rer les valeurs manquantes dans les colonnes num√©riques\n",
    "    numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "    missing_numeric = X[numeric_cols].isnull().sum()\n",
    "    cols_with_missing = missing_numeric[missing_numeric > 0].index\n",
    "\n",
    "    if len(cols_with_missing) > 0:\n",
    "        print(f\"   Remplacement des valeurs manquantes dans {len(cols_with_missing)} colonnes\")\n",
    "        for col in cols_with_missing:\n",
    "            X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "    # 4. G√©rer les valeurs infinies\n",
    "    print(f\"   Remplacement des valeurs infinies\")\n",
    "    X = X.replace([np.inf, -np.inf], np.nan)\n",
    "    X = X.fillna(X.median())\n",
    "\n",
    "    # 5. V√©rifier les colonnes constantes (variance nulle)\n",
    "    constant_cols = []\n",
    "    for col in numeric_cols:\n",
    "        if col in X.columns and X[col].nunique() <= 1:\n",
    "            constant_cols.append(col)\n",
    "\n",
    "    if constant_cols:\n",
    "        print(f\"   Suppression de {len(constant_cols)} colonnes constantes: {constant_cols}\")\n",
    "        X = X.drop(constant_cols, axis=1)\n",
    "\n",
    "    # 6. V√©rification finale\n",
    "    print(f\"   Shape final: {X.shape}\")\n",
    "    print(f\"   Toutes colonnes num√©riques: {X.dtypes.apply(lambda x: np.issubdtype(x, np.number)).all()}\")\n",
    "    print(f\"   Valeurs manquantes: {X.isnull().sum().sum()}\")\n",
    "    print(f\"   Valeurs infinies: {np.isinf(X).sum().sum()}\")\n",
    "\n",
    "    return X, y"
   ],
   "id": "9819e7e3d6c08a15",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T15:21:13.726841Z",
     "start_time": "2025-06-16T15:21:13.695311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_feature_engineering_safe(df):\n",
    "    \"\"\"Cr√©e de nouvelles features de fa√ßon s√©curis√©e\"\"\"\n",
    "\n",
    "    print(f\"\\nüîß FEATURE ENGINEERING S√âCURIS√â\")\n",
    "    df_enhanced = df.copy()\n",
    "\n",
    "    # Variables d√©riv√©es seulement si les colonnes existent\n",
    "    feature_created = 0\n",
    "\n",
    "    # Lead time features\n",
    "    if 'lead_time' in df.columns:\n",
    "        print(\"   Cr√©ation des features lead_time\")\n",
    "        # Cat√©gories de lead_time\n",
    "        df_enhanced['lead_time_very_short'] = (df['lead_time'] <= 7).astype(int)\n",
    "        df_enhanced['lead_time_short'] = ((df['lead_time'] > 7) & (df['lead_time'] <= 30)).astype(int)\n",
    "        df_enhanced['lead_time_medium'] = ((df['lead_time'] > 30) & (df['lead_time'] <= 90)).astype(int)\n",
    "        df_enhanced['lead_time_long'] = (df['lead_time'] > 90).astype(int)\n",
    "\n",
    "        # Transformation log\n",
    "        df_enhanced['lead_time_log'] = np.log1p(df['lead_time'])\n",
    "\n",
    "        # Lead time standardis√©\n",
    "        df_enhanced['lead_time_std'] = (df['lead_time'] - df['lead_time'].mean()) / (df['lead_time'].std() + 1e-8)\n",
    "\n",
    "        feature_created += 6\n",
    "\n",
    "    # Variables de nuits et guests\n",
    "    if all(col in df.columns for col in ['no_of_weekend_nights', 'no_of_week_nights']):\n",
    "        print(\"   Cr√©ation des features de s√©jour\")\n",
    "        df_enhanced['total_nights'] = df['no_of_weekend_nights'] + df['no_of_week_nights']\n",
    "        df_enhanced['weekend_ratio'] = df['no_of_weekend_nights'] / (df_enhanced['total_nights'] + 1e-8)\n",
    "        feature_created += 2\n",
    "\n",
    "    if all(col in df.columns for col in ['no_of_adults', 'no_of_children']):\n",
    "        print(\"   Cr√©ation des features d'invit√©s\")\n",
    "        df_enhanced['total_guests'] = df['no_of_adults'] + df['no_of_children']\n",
    "        df_enhanced['children_ratio'] = df['no_of_children'] / (df_enhanced['total_guests'] + 1e-8)\n",
    "        feature_created += 2\n",
    "\n",
    "    # Variables de prix\n",
    "    if 'avg_price_per_room' in df.columns:\n",
    "        print(\"   Cr√©ation des features de prix\")\n",
    "        if 'total_guests' in df_enhanced.columns:\n",
    "            df_enhanced['price_per_guest'] = df['avg_price_per_room'] / (df_enhanced['total_guests'] + 1e-8)\n",
    "        if 'total_nights' in df_enhanced.columns:\n",
    "            df_enhanced['price_per_night'] = df['avg_price_per_room'] / (df_enhanced['total_nights'] + 1e-8)\n",
    "\n",
    "        # Cat√©gories de prix\n",
    "        price_q75 = df['avg_price_per_room'].quantile(0.75)\n",
    "        df_enhanced['expensive_booking'] = (df['avg_price_per_room'] > price_q75).astype(int)\n",
    "        feature_created += 3\n",
    "\n",
    "    # Variables d'exp√©rience client\n",
    "    if all(col in df.columns for col in ['no_of_previous_bookings_not_canceled', 'no_of_previous_cancellations']):\n",
    "        print(\"   Cr√©ation des features d'exp√©rience\")\n",
    "        df_enhanced['customer_experience'] = (df['no_of_previous_bookings_not_canceled'] -\n",
    "                                            df['no_of_previous_cancellations'])\n",
    "\n",
    "        if 'repeated_guest' in df.columns:\n",
    "            df_enhanced['loyalty_score'] = df['repeated_guest'] * df_enhanced['customer_experience']\n",
    "        feature_created += 2\n",
    "\n",
    "    # Variables temporelles\n",
    "    if 'arrival_month' in df.columns:\n",
    "        print(\"   Cr√©ation des features temporelles\")\n",
    "        df_enhanced['peak_season'] = df['arrival_month'].isin([6, 7, 8, 12]).astype(int)\n",
    "        df_enhanced['low_season'] = df['arrival_month'].isin([1, 2, 11]).astype(int)\n",
    "        feature_created += 2\n",
    "\n",
    "    print(f\"   ‚úÖ {feature_created} nouvelles features cr√©√©es\")\n",
    "    print(f\"   Shape final: {df_enhanced.shape}\")\n",
    "\n",
    "    return df_enhanced"
   ],
   "id": "11364bd5b1f98f4a",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T15:21:14.779322Z",
     "start_time": "2025-06-16T15:21:13.746911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# EX√âCUTION DU DIAGNOSTIC ET NETTOYAGE\n",
    "print(\"üöÄ D√âMARRAGE DU DIAGNOSTIC\")\n",
    "\n",
    "# Chargement des donn√©es\n",
    "file_paths = [\n",
    "    'C:/Users/tneron2023/PycharmProjects/Python_IA/project_hotel/datas/Hotel_enhanced.csv',\n",
    "    'C:/Users/tneron2023/PycharmProjects/Python_IA/project_hotel/datas/Hotel_clean.csv',\n",
    "    'C:/Users/tneron2023/PycharmProjects/Python_IA/project_hotel/datas/Hotel_Reservations.csv'\n",
    "]\n",
    "\n",
    "df = None\n",
    "for file_path in file_paths:\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"‚úÖ Fichier charg√©: {file_path}\")\n",
    "        break\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "\n",
    "if df is None:\n",
    "    print(\"‚ùå Aucun fichier de donn√©es trouv√©\")\n",
    "else:\n",
    "    # Identifier la variable cible\n",
    "    target_candidates = ['booking_status_Not_Canceled', 'booking_status']\n",
    "    target = None\n",
    "    for candidate in target_candidates:\n",
    "        if candidate in df.columns:\n",
    "            target = candidate\n",
    "            break\n",
    "\n",
    "    if target is None:\n",
    "        print(\"‚ö†Ô∏è Variable cible non identifi√©e automatiquement\")\n",
    "        print(f\"Colonnes disponibles: {df.columns.tolist()}\")\n",
    "\n",
    "    # Diagnostic\n",
    "    diagnose_dataframe(df, target)\n",
    "\n",
    "    # Nettoyage\n",
    "    X_clean, y_clean = clean_dataframe(df, target)\n",
    "\n",
    "    if X_clean is not None:\n",
    "        # Feature engineering s√©curis√©\n",
    "        df_enhanced = create_feature_engineering_safe(X_clean)\n",
    "\n",
    "        # Sauvegarde du dataset nettoy√©\n",
    "        if y_clean is not None:\n",
    "            df_final = df_enhanced.copy()\n",
    "            df_final['target'] = y_clean\n",
    "        else:\n",
    "            df_final = df_enhanced\n",
    "\n",
    "        output_path = 'C:/Users/tneron2023/PycharmProjects/Python_IA/project_hotel/datas/Hotel_cleaned_safe.csv'\n",
    "        df_final.to_csv(output_path, index=False)\n",
    "        print(f\"\\nüíæ Dataset nettoy√© sauvegard√©: {output_path}\")\n",
    "\n",
    "        # Diagnostic final\n",
    "        print(f\"\\n‚úÖ NETTOYAGE TERMIN√â\")\n",
    "        print(f\"Shape original: {df.shape}\")\n",
    "        print(f\"Shape final: {df_final.shape}\")\n",
    "        print(f\"Features ajout√©es: {df_final.shape[1] - df.shape[1]}\")\n",
    "\n",
    "        # V√©rification que le dataset est pr√™t pour ML\n",
    "        if X_clean.dtypes.apply(lambda x: np.issubdtype(x, np.number)).all():\n",
    "            print(\"‚úÖ Dataset pr√™t pour Machine Learning\")\n",
    "        else:\n",
    "            print(\"‚ùå Il reste des probl√®mes dans le dataset\")\n",
    "\n",
    "print(\"\\nüéâ DIAGNOSTIC TERMIN√â!\")"
   ],
   "id": "5b7a334debdba2ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ D√âMARRAGE DU DIAGNOSTIC\n",
      "‚úÖ Fichier charg√©: C:/Users/tneron2023/PycharmProjects/Python_IA/project_hotel/datas/Hotel_clean.csv\n",
      "\n",
      "üìä DIAGNOSTIC G√âN√âRAL\n",
      "Shape: (29999, 31)\n",
      "M√©moire utilis√©e: 7.10 MB\n",
      "\n",
      "üìã TYPES DE DONN√âES:\n",
      "float64    18\n",
      "int64      13\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚ùì VALEURS MANQUANTES:\n",
      "‚úÖ Aucune valeur manquante\n",
      "\n",
      "‚ôæÔ∏è VALEURS INFINIES:\n",
      "‚úÖ Aucune valeur infinie\n",
      "\n",
      "üè∑Ô∏è VARIABLES CAT√âGORIELLES:\n",
      "‚úÖ Aucune variable cat√©gorielle\n",
      "\n",
      "üî¢ VARIABLES NUM√âRIQUES SUSPECTES (peu de valeurs uniques):\n",
      "   no_of_adults: 5 valeurs uniques - [2 1 3 0 4]\n",
      "   no_of_children: 6 valeurs uniques - [ 0  2  1  3 10  9]\n",
      "   no_of_weekend_nights: 8 valeurs uniques - [1 2 0 4 3 6 5 7]\n",
      "   required_car_parking_space: 2 valeurs uniques - [0 1]\n",
      "   arrival_year: 2 valeurs uniques - [2017 2018]\n",
      "   repeated_guest: 2 valeurs uniques - [0 1]\n",
      "   no_of_previous_cancellations: 9 valeurs uniques - [ 0  3  1  2 11  4  5 13  6]\n",
      "   no_of_special_requests: 6 valeurs uniques - [0 1 3 2 4 5]\n",
      "   type_of_meal_plan_Meal Plan 1: 2 valeurs uniques - [1. 0.]\n",
      "   type_of_meal_plan_Meal Plan 2: 2 valeurs uniques - [0. 1.]\n",
      "   type_of_meal_plan_Meal Plan 3: 2 valeurs uniques - [0. 1.]\n",
      "   type_of_meal_plan_Not Selected: 2 valeurs uniques - [0. 1.]\n",
      "   room_type_reserved_Room_Type 1: 2 valeurs uniques - [1. 0.]\n",
      "   room_type_reserved_Room_Type 2: 2 valeurs uniques - [0. 1.]\n",
      "   room_type_reserved_Room_Type 3: 2 valeurs uniques - [0. 1.]\n",
      "   room_type_reserved_Room_Type 4: 2 valeurs uniques - [0. 1.]\n",
      "   room_type_reserved_Room_Type 5: 2 valeurs uniques - [0. 1.]\n",
      "   room_type_reserved_Room_Type 6: 2 valeurs uniques - [0. 1.]\n",
      "   room_type_reserved_Room_Type 7: 2 valeurs uniques - [0. 1.]\n",
      "   market_segment_type_Aviation: 2 valeurs uniques - [0. 1.]\n",
      "   market_segment_type_Complementary: 2 valeurs uniques - [0. 1.]\n",
      "   market_segment_type_Corporate: 2 valeurs uniques - [0. 1.]\n",
      "   market_segment_type_Offline: 2 valeurs uniques - [1. 0.]\n",
      "   market_segment_type_Online: 2 valeurs uniques - [0. 1.]\n",
      "   booking_status_Not_Canceled: 2 valeurs uniques - [1. 0.]\n",
      "\n",
      "üîç COLONNES DUPLIQU√âES:\n",
      "‚úÖ Aucune colonne dupliqu√©e\n",
      "\n",
      "üéØ ANALYSE DE LA VARIABLE CIBLE 'booking_status_Not_Canceled':\n",
      "booking_status_Not_Canceled\n",
      "1.0    20184\n",
      "0.0     9815\n",
      "Name: count, dtype: int64\n",
      "Pourcentages:\n",
      "booking_status_Not_Canceled\n",
      "1.0    67.282243\n",
      "0.0    32.717757\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "üßπ NETTOYAGE AUTOMATIQUE\n",
      "   Remplacement des valeurs infinies\n",
      "   Shape final: (29999, 30)\n",
      "   Toutes colonnes num√©riques: True\n",
      "   Valeurs manquantes: 0\n",
      "   Valeurs infinies: 0\n",
      "\n",
      "üîß FEATURE ENGINEERING S√âCURIS√â\n",
      "   Cr√©ation des features lead_time\n",
      "   Cr√©ation des features de s√©jour\n",
      "   Cr√©ation des features d'invit√©s\n",
      "   Cr√©ation des features de prix\n",
      "   Cr√©ation des features d'exp√©rience\n",
      "   Cr√©ation des features temporelles\n",
      "   ‚úÖ 17 nouvelles features cr√©√©es\n",
      "   Shape final: (29999, 47)\n",
      "\n",
      "üíæ Dataset nettoy√© sauvegard√©: C:/Users/tneron2023/PycharmProjects/Python_IA/project_hotel/datas/Hotel_cleaned_safe.csv\n",
      "\n",
      "‚úÖ NETTOYAGE TERMIN√â\n",
      "Shape original: (29999, 31)\n",
      "Shape final: (29999, 48)\n",
      "Features ajout√©es: 17\n",
      "‚úÖ Dataset pr√™t pour Machine Learning\n",
      "\n",
      "üéâ DIAGNOSTIC TERMIN√â!\n"
     ]
    }
   ],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
